{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic analysis\n",
    "\n",
    "NOTE: This requires a python virtualenv already installed with the appropriate dependencies, by e.g.:\n",
    "\n",
    "`conda create -n acanaba python=3.10 numpy pandas ipykernel jupyter holoviews bokeh datashader seaborn pytables`\n",
    "\n",
    "Let's load our tracked data and calculate some basic metrics for the pre-reversal and first reversal session.\n",
    "\n",
    "First we need to import the `pandas` module which allows us to manipulate tabular data. The module provides two basic data structures, DataFrames (table-like) and Series (row-like)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `idx` object allows us to do complex indexing on our DataFrames and Series objects.\n",
    "\n",
    "Now let's load our analysed position data. Initially let's just load up the first data file and see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_fns = {'prerev': '../rawdata/sub-lizzy/sub-lizzy_ses-prerev_task-RR10_vidDLC_resnet50_dlc_acan_masterOct23shuffle1_800000.h5',\n",
    "             'rev01': '../rawdata/sub-lizzy/sub-lizzy_ses-rev01_task-RR10_vidDLC_resnet50_dlc_acan_masterOct23shuffle1_800000.h5'}\n",
    "_df = pd.read_hdf(track_fns['prerev'])\n",
    "_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is reasonable, but there seems to be an uninformative (and incorrect) 'scorer' index, and the frame number has no name. Let's fix this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df.columns = _df.columns.droplevel(0)\n",
    "_df.index.name = 'frame_id'\n",
    "_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, this looks better. Now let's make a function for this, so we can load all our data together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_track_session(filename: str) -> pd.DataFrame:\n",
    "    '''Load one session analysed by DeepLabCut into a DataFrame'''\n",
    "    df = pd.read_hdf(filename)\n",
    "    df.columns = df.columns.droplevel(0)\n",
    "    df.index.name = 'frame_id'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load all the sessions into a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_dfs = {key: load_track_session(fn) for key, fn in track_fns.items()}\n",
    "track_df = pd.concat(track_dfs, names=['session_id'])\n",
    "track_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to extract one point, let's say the animal's nose, we can index just those columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df.loc[:, idx['nose']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, if we want to see just the frames where DeepLabCut classified a point with high confidence, we can filter the results on the likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df.loc[:, idx['nose']].query('likelihood > 0.95')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the session timings.\n",
    "\n",
    "We can filter all our positional data by the first and last LED flash in each acquisition run. These values are stored in JSON files associated with each MedPC session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sidecar(filename: str) -> pd.Series:\n",
    "    with open(filename) as sidecar:\n",
    "        info = json.load(sidecar)\n",
    "    return pd.Series(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sidecar_fns = Path('../rawdata').glob('*/*.json')\n",
    "info_df = pd.DataFrame([load_sidecar(fn) for fn in sidecar_fns]).set_index(['sub', 'ses', 'acq'])\n",
    "info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can label the tracking data with the session and acquisition information.\n",
    "\n",
    "First let's look at how we can select the correct data for each acquisition session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df.loc[idx['rev01', 22647:43448], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acq_session(info):\n",
    "    df = track_df.loc[idx[info.ses, info.firston:info.laston], :]\n",
    "    df = df.assign(acq=info.acq).set_index('acq', append=True)\n",
    "    df.index = df.index.reorder_levels(['session_id', 'acq', 'frame_id'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acq_df = pd.concat([get_acq_session(info) for info in info_df.reset_index().itertuples()])\n",
    "acq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "import datashader as ds\n",
    "from holoviews.operation.datashader import datashade\n",
    "hv.extension('bokeh')\n",
    "import panel\n",
    "panel.extension(comms='vscode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nose_df = acq_df.loc[idx['rev01', 'LP', :], idx['nose']].query('likelihood > 0.95')\n",
    "datashade(hv.Path(nose_df.loc[nose_df['likelihood'] > 0.95])).opts(width=600, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {(ses, acq): hv.Path(acq_df.loc[idx[ses, acq, :], idx['nose']].query('likelihood > 0.95'))\n",
    "         for i, ses, acq in info_df.reset_index().loc[:, ['ses', 'acq']].itertuples()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.HoloMap(paths, kdims=['ses', 'acq']).layout().cols(2).opts(width=400, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the centre point of the head? We need the mean point between the two ears, filtered for only those points where the likelihoods of both points are above a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_centre_mask = (acq_df.stack().loc[idx[:, :, :, 'likelihood'], idx['leftEar', 'rightEar']] > 0.95).all(axis=1).to_numpy()\n",
    "head_centre_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_centre_df = acq_df.stack().loc[idx[:, :, :, ['x', 'y']], ['leftEar', 'rightEar']].mean(axis=1).unstack()\n",
    "head_centre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {(ses, acq): hv.Path(head_centre_df.loc[idx[ses, acq, head_centre_mask], :])\n",
    "         for i, ses, acq in info_df.reset_index().loc[:, ['ses', 'acq']].itertuples()}\n",
    "hv.HoloMap(paths, kdims=['ses', 'acq']).layout().cols(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're plotting trajectories, but what about dwell times? Occupancy maps can give us dwell time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spatial\n",
    "bins = np.array((40, 40))\n",
    "minmax = [head_centre_df.loc[head_centre_mask, ['x', 'y']].min(),\n",
    "          head_centre_df.loc[head_centre_mask, ['x', 'y']].max()]\n",
    "path_range = [(a, b) for a, b in zip(*minmax)]\n",
    "head_centre_df['t'] = head_centre_df.index.get_level_values('frame_id') / 30\n",
    "_df = head_centre_df.loc[head_centre_mask, ['t', 'x', 'y']]\n",
    "occ = spatial.occupancy_map(_df.loc[idx['prerev', 'LG', :]].to_numpy(),\n",
    "                            bins=bins, smooth=1, max_dt=0.2,\n",
    "                            range=path_range)\n",
    "hv.Image(occ.hist.T).opts(cmap='viridis', frame_height=400,\n",
    "                          data_aspect=(bins[1]/bins[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('acanbehave')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38c0db2b5ca17c1c4aac225b47f1dc3192e0458b2f2f724aaf9a19882846a9a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
